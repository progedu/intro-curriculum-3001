{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colaboratory へようこそ",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takemr/intro-curriculum-3001/blob/master/dicomo_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER5adzFhoJya",
        "colab_type": "code",
        "outputId": "d02ab760-f67a-4fab-ace9-4f9c19ca212c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5222
        }
      },
      "source": [
        "#cloud\n",
        "import os\n",
        "import csv\n",
        "from urllib.request import urlretrieve\n",
        "from urllib.parse import urlparse\n",
        "from zipfile import ZipFile\n",
        "from tensorflow.contrib import rnn\n",
        "\n",
        "###Air Qualityのダウンロード###\n",
        "def download_file(url, output_dir, overwrite=False):\n",
        "  # URLからファイル名を取得\n",
        "  parse_result = urlparse(url)\n",
        "  file_name = os.path.basename(parse_result.path)\n",
        "  # 出力先ファイルパス\n",
        "  destination = os.path.join(output_dir, file_name)\n",
        "\n",
        "  # 無意味なダウンロードを防ぐため、上書き（overwrite）の指定か未ダウンロードの場合のみダウンロードを実施する\n",
        "  if overwrite or not os.path.exists(destination):\n",
        "    # 出力先ディレクトリの作成\n",
        "    os.makedirs(output_dir)\n",
        "    # ダウンロード\n",
        "    urlretrieve(url, destination)\n",
        "\n",
        "  return destination\n",
        "\n",
        "zip_file = download_file('https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip', 'UCI_data/')\n",
        "###ZipFile→AirQualityUCI.xlsx→air_quality\n",
        "import pandas as pd\n",
        "\n",
        "with ZipFile(zip_file) as z:\n",
        " with z.open('AirQualityUCI.xlsx') as f:\n",
        "   air_quality = pd.read_excel(\n",
        "     f,\n",
        "     index_col=0, parse_dates={'DateTime': [0, 1]}, #1\n",
        "     na_values=[-200.0],                            #2\n",
        "     convert_float=False                            #3\n",
        "   )\n",
        "\n",
        "#初期のAirQuality　（欠損値は削除済）\n",
        "#print(\"air_quality\")\n",
        "#print(air_quality)\n",
        "\n",
        "\n",
        "#import cufflinks as cf\n",
        "#cf.go_offline()\n",
        "\n",
        "# 不要列の除去\n",
        "target_columns = ['T', 'AH', 'PT08.S1(CO)', 'PT08.S2(NMHC)', 'PT08.S3(NOx)', 'PT08.S4(NO2)']\n",
        "air_quality = air_quality[target_columns]\n",
        "#不要列削除後のAirQuality\n",
        "#print(\"air_quality\")\n",
        "#print(air_quality)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### TimeSriesDataSetクラスの定義 ###\n",
        "import numpy as np\n",
        "\n",
        "# 乱数シードの初期化（数値は何でもよい）\n",
        "np.random.seed(12345)\n",
        "\n",
        "# クラス定義\n",
        "class TimeSeriesDataSet:\n",
        "\n",
        " def __init__(self, dataframe):\n",
        "   self.feature_count = len(dataframe.columns)\n",
        "   self.series_length = len(dataframe)\n",
        "   self.series_data = dataframe.astype('float32')\n",
        "\n",
        "\n",
        " def __getitem__(self, n):\n",
        "   return TimeSeriesDataSet(self.series_data[n])\n",
        "\n",
        "\n",
        " def __len__(self):\n",
        "   return len(self.series_data)\n",
        "\n",
        "\n",
        " @property\n",
        "\n",
        " def times(self):\n",
        "   return self.series_data.index\n",
        "\n",
        "\n",
        " def next_batch(self, length, batch_size):\n",
        "   \"\"\"\n",
        "   連続したlength時間のデータおよび1時間の誤差測定用データを取得する。\n",
        "   最後の1時間は最終出力データ。\n",
        "   \"\"\"\n",
        "   max_start_index = len(self) - length\n",
        "   design_matrix = []\n",
        "   expectation = []\n",
        "   while len(design_matrix) < batch_size:\n",
        "     start_index = np.random.choice(max_start_index)\n",
        "     end_index = start_index + length + 1\n",
        "     values = self.series_data[start_index:end_index]\n",
        "     if (values.count() == length + 1).all():  # 切り出したデータ中に欠損値がない\n",
        "       train_data = values[:-1]\n",
        "       true_value = values[-1:]\n",
        "       design_matrix.append(train_data.as_matrix())\n",
        "       expectation.append(np.reshape(true_value.as_matrix(), [self.feature_count]))\n",
        "   return np.stack(design_matrix), np.stack(expectation)\n",
        "\n",
        " def append(self, data_point):\n",
        "   dataframe = pd.DataFrame(data_point, columns=self.series_data.columns)\n",
        "   self.series_data = self.series_data.append(dataframe)\n",
        "\n",
        " def tail(self, n):\n",
        "   return TimeSeriesDataSet(self.series_data.tail(n))\n",
        "\n",
        " def as_array(self):\n",
        "   return np.stack([self.series_data.as_matrix()])\n",
        "\n",
        " def mean(self):\n",
        "   return self.series_data.mean()\n",
        "\n",
        " def std(self):\n",
        "   return self.series_data.std()\n",
        "\n",
        " def standardize(self, mean=None, std=None):\n",
        "   if mean is None:\n",
        "     mean = self.mean()\n",
        "   if std is None:\n",
        "     std = self.std()\n",
        "   return TimeSeriesDataSet((self.series_data - mean) / std)\n",
        "\n",
        "\n",
        "\n",
        "###air_quality→dataset（TimeSeriesDataSetクラス）###\n",
        "dataset = TimeSeriesDataSet(air_quality)\n",
        "train_dataset = dataset[dataset.times.year < 2005]\n",
        "leak_dataset = train_dataset[4<=train_dataset.times.month]\n",
        "leak_dataset = leak_dataset[leak_dataset.times.month<=6]\n",
        "test_dataset = dataset[dataset.times.year >= 2005]\n",
        "\n",
        "#dataset\n",
        "#print(\"dataset\")\n",
        "#print(dataset.series_data)\n",
        "\n",
        "#generate original model\n",
        "import tensorflow as tf\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# 再現性の確保のために乱数シードを固定\n",
        "tf.set_random_seed(12345)\n",
        "\n",
        "# パラメーター\n",
        "# 学習時間長\n",
        "SERIES_LENGTH = 72\n",
        "# 特徴量数\n",
        "FEATURE_COUNT = dataset.feature_count #6種類\n",
        "\n",
        "# 入力（placeholderメソッドの引数は、データ型、テンソルのサイズ）\n",
        "# 訓練データ\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, SERIES_LENGTH, FEATURE_COUNT]) #batch_size（16） × 72 × 6\n",
        "# 教師データ\n",
        "y = tf.placeholder(tf.float32, [None, FEATURE_COUNT]) #batch_size（16） × 6\n",
        "\n",
        "# RNNセルの作成\n",
        "cell = tf.nn.rnn_cell.BasicLSTMCell(20)\n",
        "initial_state = cell.zero_state(tf.shape(x)[0], dtype=tf.float32)\n",
        "outputs, last_state = tf.nn.dynamic_rnn(cell, x, initial_state=initial_state, dtype=tf.float32)\n",
        "\n",
        "# 全結合\n",
        "# 重み\n",
        "w = tf.Variable(tf.zeros([20, FEATURE_COUNT])) #w  20×6\n",
        "# バイアス\n",
        "b = tf.Variable([0.1] * FEATURE_COUNT) #6\n",
        "# 最終出力（予測）\n",
        "prediction = tf.matmul(last_state[-1], w) + b\n",
        "\n",
        "# 損失関数（平均絶対誤差：MAE）と最適化（Adam）\n",
        "loss = tf.reduce_mean(tf.map_fn(tf.abs, y - prediction))\n",
        "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
        "\n",
        "# バッチサイズ\n",
        "BATCH_SIZE = 16\n",
        "# 学習回数\n",
        "NUM_TRAIN =  10000 #ほんとは10000\n",
        "# 学習中の出力頻度\n",
        "OUTPUT_BY = 500\n",
        "\n",
        "# 標準化\n",
        "train_mean = train_dataset.mean()\n",
        "train_std = train_dataset.std()\n",
        "standardized_train_dataset = train_dataset.standardize() #train_dataset はこの形で今後処理を行う\n",
        "\n",
        "#standardized_train_dataset\n",
        "#print(\"standardized_train_dataset\")\n",
        "#print(standardized_train_dataset.series_data)\n",
        "\n",
        "# 学習の実行\n",
        "sess.run(tf.global_variables_initializer())\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_train_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE)\n",
        "\n",
        " mae, _ = sess.run([loss, optimizer], feed_dict={x: batch[0], y: batch[1]})\n",
        "\n",
        " if i % OUTPUT_BY == 0:\n",
        "   print('step {:d}, error {:.2f}'.format(i, mae))\n",
        "\n",
        "#f = open('leak.csv', 'w')\n",
        "#cw = csv.writer(f)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###prediction###\n",
        "def rnn_predict(input_dataset):\n",
        "   # 標準化\n",
        "   previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=train_mean, std=train_std)\n",
        "   # 予測対象の時刻\n",
        "   #print(\"aaa\")\n",
        "   #print(previous.times[0])\n",
        "   #print(previous.times[-1])\n",
        "   predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "   #print(\"predict_time\")\n",
        "   #print(predict_time)\n",
        "   # 予測\n",
        "   batch_x = previous.as_array()\n",
        "   predict_data = prediction.eval({x: batch_x})\n",
        "   \n",
        "   # 結果のデータフレームを作成\n",
        "   df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        "   # 標準化の逆操作\n",
        "   return train_mean + train_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in leak_dataset.times:\n",
        "   predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        "   #print(\"predict_result\")\n",
        "   #print(predict_result)\n",
        "   #print(\"answear\") #よう分からんしいらん\n",
        "   #print(test_dataset[test_dataset.times == current_time].series_data)\n",
        "   predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "predict_air_quality.to_csv('leak.csv')\n",
        "\n",
        "print(\"1正解leak\")\n",
        "print(leak_dataset.series_data)\n",
        "print(\"モデルleak\")\n",
        "print(predict_air_quality)\n",
        "#hyouka\n",
        "absmean = np.mean(abs(leak_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "      \n",
        "#abs = abs(test_dataset.series_data - predict_air_quality)\n",
        "\n",
        "#print(tf.reduce_mean(tf.map_fn(test_dataset.series_data - predict_air_quality)))\n",
        "\n",
        "\"\"\"\n",
        "###One to Many\n",
        "from functools import reduce\n",
        "import re\n",
        "\n",
        "def rnn_predict(input_dataset, ahead=1):\n",
        "  # 標準化\n",
        "  buffer = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=train_mean, std=train_std)\n",
        "  # 予測対象の時刻\n",
        "  last_time = buffer.times[-1]\n",
        "\n",
        "  # 予測\n",
        "  predict_data = []\n",
        "  for i in range(0, ahead):\n",
        "    batch_x = buffer.tail(SERIES_LENGTH).as_array()\n",
        "    result_array = prediction.eval({x: batch_x})\n",
        "    predict_data.append(result_array)\n",
        "    buffer.append(result_array)\n",
        "  predict_data = reduce(lambda acc, x: np.concatenate((acc, x)), predict_data)\n",
        "\n",
        "  # インデックス時刻の作成\n",
        "  hour = np.timedelta64(1, 'h')\n",
        "  first_predict_time = input_dataset.index[-1] + hour\n",
        "  index = np.arange(first_predict_time, first_predict_time + ahead * hour, step=hour)\n",
        "\n",
        "  # 結果のデータフレームを作成\n",
        "  df_standardized = pd.DataFrame(predict_data, columns=input_dataset.columns, index=index)\n",
        "  # 標準化の逆操作\n",
        "  return train_mean + train_std * df_standardized\n",
        "\n",
        "predict_air_quality_1 = pd.DataFrame([], columns=air_quality.columns)\n",
        "predict_air_quality_2 = pd.DataFrame([], columns=air_quality.columns)\n",
        "predict_air_quality_3 = pd.DataFrame([], columns=air_quality.columns)\n",
        "predict_air_quality_4 = pd.DataFrame([], columns=air_quality.columns)\n",
        "predict_air_quality_5 = pd.DataFrame([], columns=air_quality.columns)\n",
        "predict_air_quality_6 = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in dataset.times[dataset.times.year >= 2005]:\n",
        "  # 6時間先まで予測（結果は6レコード）\n",
        "  predict_result = rnn_predict(air_quality[air_quality.index < current_time], 6)\n",
        "  # 1時間先の予測レコード\n",
        "  predict_air_quality_1 = predict_air_quality_1.append(predict_result[0:1])\n",
        "  # 2時間先の予測レコード\n",
        "  predict_air_quality_2 = predict_air_quality_2.append(predict_result[1:2])\n",
        "  # 3時間先の予測レコード\n",
        "  predict_air_quality_3 = predict_air_quality_3.append(predict_result[2:3])\n",
        "  # 4時間先の予測レコード\n",
        "  predict_air_quality_4 = predict_air_quality_4.append(predict_result[3:4])\n",
        "  # 5時間先の予測レコード\n",
        "  predict_air_quality_5 = predict_air_quality_5.append(predict_result[4:5])\n",
        "  #6時間先の予測レコード\n",
        "  predict_air_quality_6 = predict_air_quality_6.append(predict_result[5:6])\n",
        "\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality_1))\n",
        "print(\"1 hour later\")\n",
        "print(1-(absmean['T']/18.316054))\n",
        "print(1-(absmean['AH']/1.025530))\n",
        "print(1-(absmean['PT08.S1(CO)']/1099.707856))\n",
        "print(1-(absmean['PT08.S2(NMHC)']/939.029205))\n",
        "print(1-(absmean['PT08.S3(NOx)']/835.370973))\n",
        "print(1-(absmean['PT08.S4(NO2)']/1456.143486))\n",
        "\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality_2))\n",
        "print(\"2 hour later\")\n",
        "print(1-(absmean['T']/18.316054))\n",
        "print(1-(absmean['AH']/1.025530))\n",
        "print(1-(absmean['PT08.S1(CO)']/1099.707856))\n",
        "print(1-(absmean['PT08.S2(NMHC)']/939.029205))\n",
        "print(1-(absmean['PT08.S3(NOx)']/835.370973))\n",
        "print(1-(absmean['PT08.S4(NO2)']/1456.143486))\n",
        "\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality_3))\n",
        "print(\"3 hour later\")\n",
        "print(1-(absmean['T']/18.316054))\n",
        "print(1-(absmean['AH']/1.025530))\n",
        "print(1-(absmean['PT08.S1(CO)']/1099.707856))\n",
        "print(1-(absmean['PT08.S2(NMHC)']/939.029205))\n",
        "print(1-(absmean['PT08.S3(NOx)']/835.370973))\n",
        "print(1-(absmean['PT08.S4(NO2)']/1456.143486))\n",
        "\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality_4))\n",
        "print(\"4 hour later\")\n",
        "print(1-(absmean['T']/18.316054))\n",
        "print(1-(absmean['AH']/1.025530))\n",
        "print(1-(absmean['PT08.S1(CO)']/1099.707856))\n",
        "print(1-(absmean['PT08.S2(NMHC)']/939.029205))\n",
        "print(1-(absmean['PT08.S3(NOx)']/835.370973))\n",
        "print(1-(absmean['PT08.S4(NO2)']/1456.143486))\n",
        "\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality_5))\n",
        "print(\"5 hour later\")\n",
        "print(1-(absmean['T']/18.316054))\n",
        "print(1-(absmean['AH']/1.025530))\n",
        "print(1-(absmean['PT08.S1(CO)']/1099.707856))\n",
        "print(1-(absmean['PT08.S2(NMHC)']/939.029205))\n",
        "print(1-(absmean['PT08.S3(NOx)']/835.370973))\n",
        "print(1-(absmean['PT08.S4(NO2)']/1456.143486))\n",
        "\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality_6))\n",
        "print(\"6 hour later\")\n",
        "print(1-(absmean['T']/18.316054))\n",
        "print(1-(absmean['AH']/1.025530))\n",
        "print(1-(absmean['PT08.S1(CO)']/1099.707856))\n",
        "print(1-(absmean['PT08.S2(NMHC)']/939.029205))\n",
        "print(1-(absmean['PT08.S3(NOx)']/835.370973))\n",
        "print(1-(absmean['PT08.S4(NO2)']/1456.143486))\n",
        "\"\"\"\n",
        "sess.close()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-24fd6dc2d1df>:163: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-1-24fd6dc2d1df>:165: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:103: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 0, error 0.87\n",
            "step 500, error 0.31\n",
            "step 1000, error 0.25\n",
            "step 1500, error 0.19\n",
            "step 2000, error 0.23\n",
            "step 2500, error 0.30\n",
            "step 3000, error 0.16\n",
            "step 3500, error 0.14\n",
            "step 4000, error 0.22\n",
            "step 4500, error 0.25\n",
            "step 5000, error 0.19\n",
            "step 5500, error 0.22\n",
            "step 6000, error 0.17\n",
            "step 6500, error 0.17\n",
            "step 7000, error 0.20\n",
            "step 7500, error 0.25\n",
            "step 8000, error 0.26\n",
            "step 8500, error 0.18\n",
            "step 9000, error 0.24\n",
            "step 9500, error 0.24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:114: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1正解leak\n",
            "                             T        AH  PT08.S1(CO)  PT08.S2(NMHC)  \\\n",
            "DateTime                                                               \n",
            "2004-04-01 00:00:00  11.950000  0.859344  1143.000000     825.250000   \n",
            "2004-04-01 01:00:00  11.500000  0.865156  1043.750000     769.500000   \n",
            "2004-04-01 02:00:00  10.675000  0.862988  1034.000000     715.500000   \n",
            "2004-04-01 03:00:00   8.974999  0.839403   956.250000     713.250000   \n",
            "2004-04-01 04:00:00  10.225000  0.829898   909.250000     615.000000   \n",
            "2004-04-01 05:00:00  10.950000  0.832514   996.000000     648.250000   \n",
            "2004-04-01 06:00:00   9.625000  0.824264  1153.500000     876.000000   \n",
            "2004-04-01 07:00:00   9.500000  0.827329  1510.250000    1290.500000   \n",
            "2004-04-01 08:00:00  11.875000  0.845475  1721.500000    1595.250000   \n",
            "2004-04-01 09:00:00  16.225000  0.889207  1511.500000    1323.250000   \n",
            "2004-04-01 10:00:00  19.150000  0.869266  1258.250000    1039.750000   \n",
            "2004-04-01 11:00:00  19.725000  0.874324  1093.750000     849.500000   \n",
            "2004-04-01 12:00:00  20.600000  0.879714  1128.750000     875.250000   \n",
            "2004-04-01 13:00:00  21.849998  0.877140  1124.500000     923.500000   \n",
            "2004-04-01 14:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 15:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 16:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 17:00:00  23.600000  0.791260  1308.000000    1192.666626   \n",
            "2004-04-01 18:00:00  22.850000  0.881361  1528.500000    1330.750000   \n",
            "2004-04-01 19:00:00  20.750000  0.887778  1592.250000    1429.250000   \n",
            "2004-04-01 20:00:00  18.250000  0.849342  1535.750000    1302.250000   \n",
            "2004-04-01 21:00:00  16.775000  0.834144  1192.250000    1007.000000   \n",
            "2004-04-01 22:00:00  15.825000  0.856884  1186.000000     975.500000   \n",
            "2004-04-01 23:00:00  14.900000  0.875669  1202.750000     920.250000   \n",
            "2004-04-02 00:00:00  14.075000  0.870147  1139.000000     898.500000   \n",
            "2004-04-02 01:00:00  13.250000  0.892212  1072.250000     794.500000   \n",
            "2004-04-02 02:00:00  13.250000  0.922912   954.250000     667.000000   \n",
            "2004-04-02 03:00:00  11.775000  0.886904   951.250000     672.500000   \n",
            "2004-04-02 04:00:00  11.225000  0.877466   925.500000     637.500000   \n",
            "2004-04-02 05:00:00  11.275000  0.973757   968.000000     628.250000   \n",
            "...                        ...       ...          ...            ...   \n",
            "2004-06-29 18:00:00  36.950001  1.709874  1371.500000    1381.750000   \n",
            "2004-06-29 19:00:00  34.700001  1.732487  1443.000000    1443.000000   \n",
            "2004-06-29 20:00:00  31.925001  1.789743  1200.250000    1126.000000   \n",
            "2004-06-29 21:00:00  30.500000  1.817338  1215.500000    1129.500000   \n",
            "2004-06-29 22:00:00  29.299999  1.836221  1160.250000    1070.000000   \n",
            "2004-06-29 23:00:00  28.250000  1.814352  1193.500000    1105.500000   \n",
            "2004-06-30 00:00:00  27.349998  1.828728  1198.500000    1087.000000   \n",
            "2004-06-30 01:00:00  26.766666  1.814094   964.666687     818.333313   \n",
            "2004-06-30 02:00:00  25.975000  1.814080   961.250000     800.750000   \n",
            "2004-06-30 03:00:00  26.850000  1.805823   901.250000     696.500000   \n",
            "2004-06-30 04:00:00  26.875000  1.804973   863.500000     628.750000   \n",
            "2004-06-30 05:00:00  24.575001  1.801287   951.500000     742.000000   \n",
            "2004-06-30 06:00:00  26.375000  1.798708  1008.750000     875.000000   \n",
            "2004-06-30 07:00:00  27.250000  1.654213  1224.750000    1154.500000   \n",
            "2004-06-30 08:00:00  28.449999  1.544172  1245.000000    1202.250000   \n",
            "2004-06-30 09:00:00  30.775000  1.616886  1265.250000    1209.000000   \n",
            "2004-06-30 10:00:00  34.224998  1.625164  1276.250000    1240.750000   \n",
            "2004-06-30 11:00:00  36.974998  1.635153  1232.250000    1182.500000   \n",
            "2004-06-30 12:00:00  36.599998  1.675959  1192.750000    1097.000000   \n",
            "2004-06-30 13:00:00  36.875000  1.647705  1161.750000    1117.000000   \n",
            "2004-06-30 14:00:00  39.275002  1.551956  1126.000000    1097.000000   \n",
            "2004-06-30 15:00:00  38.500000  1.501822  1089.000000     993.250000   \n",
            "2004-06-30 16:00:00  39.724998  1.459373  1134.000000    1072.500000   \n",
            "2004-06-30 17:00:00  38.774998  1.643250  1388.250000    1417.500000   \n",
            "2004-06-30 18:00:00  33.549999  1.938953  1505.500000    1499.000000   \n",
            "2004-06-30 19:00:00  34.024998  1.725074  1351.750000    1385.000000   \n",
            "2004-06-30 20:00:00  31.900002  1.566288  1216.500000    1226.750000   \n",
            "2004-06-30 21:00:00  30.200001  1.586963  1148.500000    1132.250000   \n",
            "2004-06-30 22:00:00  28.924999  1.609607  1156.000000    1128.750000   \n",
            "2004-06-30 23:00:00  27.775000  1.660439  1179.750000    1121.500000   \n",
            "\n",
            "                     PT08.S3(NOx)  PT08.S4(NO2)  \n",
            "DateTime                                         \n",
            "2004-04-01 00:00:00    985.500000   1477.250000  \n",
            "2004-04-01 01:00:00   1031.250000   1424.750000  \n",
            "2004-04-01 02:00:00   1085.000000   1405.000000  \n",
            "2004-04-01 03:00:00   1098.500000   1421.500000  \n",
            "2004-04-01 04:00:00   1237.000000   1321.500000  \n",
            "2004-04-01 05:00:00   1175.500000   1339.750000  \n",
            "2004-04-01 06:00:00   1001.500000   1560.500000  \n",
            "2004-04-01 07:00:00    675.250000   1949.000000  \n",
            "2004-04-01 08:00:00    538.750000   2438.500000  \n",
            "2004-04-01 09:00:00    631.000000   2001.000000  \n",
            "2004-04-01 10:00:00    799.500000   1700.750000  \n",
            "2004-04-01 11:00:00    970.250000   1488.750000  \n",
            "2004-04-01 12:00:00    974.000000   1523.750000  \n",
            "2004-04-01 13:00:00    936.500000   1541.500000  \n",
            "2004-04-01 14:00:00           NaN           NaN  \n",
            "2004-04-01 15:00:00           NaN           NaN  \n",
            "2004-04-01 16:00:00           NaN           NaN  \n",
            "2004-04-01 17:00:00    793.333313   1193.000000  \n",
            "2004-04-01 18:00:00    700.250000   2028.250000  \n",
            "2004-04-01 19:00:00    623.750000   2089.000000  \n",
            "2004-04-01 20:00:00    666.000000   1921.750000  \n",
            "2004-04-01 21:00:00    827.000000   1604.000000  \n",
            "2004-04-01 22:00:00    844.000000   1570.250000  \n",
            "2004-04-01 23:00:00    897.750000   1528.500000  \n",
            "2004-04-02 00:00:00    921.250000   1514.250000  \n",
            "2004-04-02 01:00:00    985.500000   1441.750000  \n",
            "2004-04-02 02:00:00   1179.500000   1350.250000  \n",
            "2004-04-02 03:00:00   1137.000000   1380.750000  \n",
            "2004-04-02 04:00:00   1195.000000   1342.250000  \n",
            "2004-04-02 05:00:00   1196.500000   1371.500000  \n",
            "...                           ...           ...  \n",
            "2004-06-29 18:00:00    567.750000   2267.500000  \n",
            "2004-06-29 19:00:00    543.250000   2331.500000  \n",
            "2004-06-29 20:00:00    663.500000   1979.250000  \n",
            "2004-06-29 21:00:00    654.500000   1993.750000  \n",
            "2004-06-29 22:00:00    686.750000   1928.500000  \n",
            "2004-06-29 23:00:00    667.250000   1984.500000  \n",
            "2004-06-30 00:00:00    658.250000   1954.000000  \n",
            "2004-06-30 01:00:00    844.000000   1681.333374  \n",
            "2004-06-30 02:00:00    850.000000   1683.000000  \n",
            "2004-06-30 03:00:00    951.750000   1585.500000  \n",
            "2004-06-30 04:00:00   1052.000000   1557.500000  \n",
            "2004-06-30 05:00:00    892.000000   1656.250000  \n",
            "2004-06-30 06:00:00    797.250000   1738.000000  \n",
            "2004-06-30 07:00:00    642.750000   1991.750000  \n",
            "2004-06-30 08:00:00    628.000000   2039.250000  \n",
            "2004-06-30 09:00:00    637.750000   2014.500000  \n",
            "2004-06-30 10:00:00    641.500000   2024.250000  \n",
            "2004-06-30 11:00:00    675.250000   1920.250000  \n",
            "2004-06-30 12:00:00    698.000000   1831.500000  \n",
            "2004-06-30 13:00:00    700.000000   1856.500000  \n",
            "2004-06-30 14:00:00    722.500000   1810.250000  \n",
            "2004-06-30 15:00:00    800.500000   1675.000000  \n",
            "2004-06-30 16:00:00    746.500000   1764.750000  \n",
            "2004-06-30 17:00:00    567.500000   2249.750000  \n",
            "2004-06-30 18:00:00    505.750000   2485.000000  \n",
            "2004-06-30 19:00:00    562.500000   2205.000000  \n",
            "2004-06-30 20:00:00    641.000000   2039.750000  \n",
            "2004-06-30 21:00:00    687.750000   1935.500000  \n",
            "2004-06-30 22:00:00    688.250000   1941.000000  \n",
            "2004-06-30 23:00:00    678.250000   1921.250000  \n",
            "\n",
            "[2184 rows x 6 columns]\n",
            "モデルleak\n",
            "                             T        AH  PT08.S1(CO)  PT08.S2(NMHC)  \\\n",
            "2004-04-01 00:00:00  11.848707  0.829585  1003.797302     759.865906   \n",
            "2004-04-01 01:00:00  11.837768  0.886434  1073.750244     818.403687   \n",
            "2004-04-01 02:00:00  11.255680  0.869652   974.762085     700.252075   \n",
            "2004-04-01 03:00:00  10.570814  0.872321   959.899902     667.204346   \n",
            "2004-04-01 04:00:00   8.993267  0.846044   896.973999     624.407471   \n",
            "2004-04-01 05:00:00  10.340778  0.824634   873.972656     594.039612   \n",
            "2004-04-01 06:00:00  11.194195  0.829192  1016.491882     747.601624   \n",
            "2004-04-01 07:00:00  10.440834  0.840399  1305.829956    1101.172363   \n",
            "2004-04-01 08:00:00  11.415447  0.838755  1640.973755    1499.797241   \n",
            "2004-04-01 09:00:00  14.042244  0.836154  1501.364746    1344.646240   \n",
            "2004-04-01 10:00:00  18.673229  0.841635  1363.823730    1150.926270   \n",
            "2004-04-01 11:00:00  19.694321  0.823264  1224.528564     992.248779   \n",
            "2004-04-01 12:00:00  19.662710  0.844555  1138.032715     897.153198   \n",
            "2004-04-01 13:00:00  21.092724  0.855684  1156.313965     932.008789   \n",
            "2004-04-01 14:00:00  22.182039  0.841422  1149.167358     944.444458   \n",
            "2004-04-01 15:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 16:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 17:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 18:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 19:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 20:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 21:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 22:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 23:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-02 00:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-02 01:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-02 02:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-02 03:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-02 04:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-02 05:00:00        NaN       NaN          NaN            NaN   \n",
            "...                        ...       ...          ...            ...   \n",
            "2004-06-29 18:00:00  35.393940  1.647656  1321.570068    1328.962402   \n",
            "2004-06-29 19:00:00  35.092628  1.708690  1317.119873    1330.875610   \n",
            "2004-06-29 20:00:00  33.277916  1.719863  1333.559570    1347.756226   \n",
            "2004-06-29 21:00:00  29.750090  1.775487  1151.275146    1063.910156   \n",
            "2004-06-29 22:00:00  29.748539  1.805523  1157.340820    1101.106934   \n",
            "2004-06-29 23:00:00  28.087948  1.821829  1099.950562    1024.322632   \n",
            "2004-06-30 00:00:00  27.660856  1.798853  1100.601929    1048.752808   \n",
            "2004-06-30 01:00:00  26.729397  1.822515  1089.766235    1006.520264   \n",
            "2004-06-30 02:00:00  25.533558  1.782590   913.424072     735.421631   \n",
            "2004-06-30 03:00:00  25.735052  1.789538   898.921753     712.189453   \n",
            "2004-06-30 04:00:00  26.643253  1.791633   855.728394     638.543762   \n",
            "2004-06-30 05:00:00  26.492052  1.798595   847.430115     617.070251   \n",
            "2004-06-30 06:00:00  24.570927  1.779976   988.617493     830.153381   \n",
            "2004-06-30 07:00:00  27.068108  1.777841  1190.475464    1113.971191   \n",
            "2004-06-30 08:00:00  29.110855  1.631191  1370.865479    1391.160156   \n",
            "2004-06-30 09:00:00  30.425911  1.480365  1151.857910    1106.669067   \n",
            "2004-06-30 10:00:00  34.023300  1.641853  1178.158325    1105.020752   \n",
            "2004-06-30 11:00:00  37.059258  1.590128  1186.631104    1150.197388   \n",
            "2004-06-30 12:00:00  39.194885  1.595036  1174.958496    1127.011108   \n",
            "2004-06-30 13:00:00  38.204094  1.648549  1164.804565    1078.367920   \n",
            "2004-06-30 14:00:00  38.101982  1.607734  1158.293335    1106.201416   \n",
            "2004-06-30 15:00:00  39.644638  1.491117  1146.502441    1128.869507   \n",
            "2004-06-30 16:00:00  38.272430  1.467398  1139.057617    1083.143555   \n",
            "2004-06-30 17:00:00  38.151070  1.439455  1196.594360    1163.835449   \n",
            "2004-06-30 18:00:00  36.551216  1.689377  1362.139893    1372.909912   \n",
            "2004-06-30 19:00:00  31.252104  1.950691  1364.517700    1322.241211   \n",
            "2004-06-30 20:00:00  33.253300  1.625263  1256.950806    1287.899292   \n",
            "2004-06-30 21:00:00  29.955578  1.548852  1131.653931    1135.912109   \n",
            "2004-06-30 22:00:00  28.832504  1.596884  1090.979858    1072.546265   \n",
            "2004-06-30 23:00:00  27.763039  1.614897  1081.573975    1064.724365   \n",
            "\n",
            "                     PT08.S3(NOx)  PT08.S4(NO2)  \n",
            "2004-04-01 00:00:00   1110.022949   1408.794678  \n",
            "2004-04-01 01:00:00   1018.522095   1466.822632  \n",
            "2004-04-01 02:00:00   1122.915161   1360.833862  \n",
            "2004-04-01 03:00:00   1170.207520   1349.676147  \n",
            "2004-04-01 04:00:00   1209.539917   1323.436035  \n",
            "2004-04-01 05:00:00   1298.904297   1307.737305  \n",
            "2004-04-01 06:00:00   1117.771484   1434.421021  \n",
            "2004-04-01 07:00:00    816.038574   1787.891235  \n",
            "2004-04-01 08:00:00    558.916687   2213.570801  \n",
            "2004-04-01 09:00:00    688.604614   2052.629639  \n",
            "2004-04-01 10:00:00    751.924561   1802.691040  \n",
            "2004-04-01 11:00:00    872.424927   1628.441284  \n",
            "2004-04-01 12:00:00    963.768066   1545.820923  \n",
            "2004-04-01 13:00:00    939.578003   1580.647217  \n",
            "2004-04-01 14:00:00    926.522278   1579.608765  \n",
            "2004-04-01 15:00:00           NaN           NaN  \n",
            "2004-04-01 16:00:00           NaN           NaN  \n",
            "2004-04-01 17:00:00           NaN           NaN  \n",
            "2004-04-01 18:00:00           NaN           NaN  \n",
            "2004-04-01 19:00:00           NaN           NaN  \n",
            "2004-04-01 20:00:00           NaN           NaN  \n",
            "2004-04-01 21:00:00           NaN           NaN  \n",
            "2004-04-01 22:00:00           NaN           NaN  \n",
            "2004-04-01 23:00:00           NaN           NaN  \n",
            "2004-04-02 00:00:00           NaN           NaN  \n",
            "2004-04-02 01:00:00           NaN           NaN  \n",
            "2004-04-02 02:00:00           NaN           NaN  \n",
            "2004-04-02 03:00:00           NaN           NaN  \n",
            "2004-04-02 04:00:00           NaN           NaN  \n",
            "2004-04-02 05:00:00           NaN           NaN  \n",
            "...                           ...           ...  \n",
            "2004-06-29 18:00:00    606.936401   2130.251953  \n",
            "2004-06-29 19:00:00    610.098572   2167.537598  \n",
            "2004-06-29 20:00:00    600.298584   2185.527344  \n",
            "2004-06-29 21:00:00    711.312866   1915.538086  \n",
            "2004-06-29 22:00:00    658.671387   1954.314941  \n",
            "2004-06-29 23:00:00    701.682251   1889.884399  \n",
            "2004-06-30 00:00:00    688.486389   1909.768799  \n",
            "2004-06-30 01:00:00    713.232971   1875.242188  \n",
            "2004-06-30 02:00:00    940.698181   1636.257202  \n",
            "2004-06-30 03:00:00    950.168396   1617.009399  \n",
            "2004-06-30 04:00:00   1017.412842   1558.803345  \n",
            "2004-06-30 05:00:00   1057.958984   1549.940063  \n",
            "2004-06-30 06:00:00    797.671814   1707.534424  \n",
            "2004-06-30 07:00:00    635.805115   2008.013916  \n",
            "2004-06-30 08:00:00    531.693848   2249.242188  \n",
            "2004-06-30 09:00:00    702.460693   1882.007690  \n",
            "2004-06-30 10:00:00    693.040771   1895.069336  \n",
            "2004-06-30 11:00:00    690.131714   1900.255615  \n",
            "2004-06-30 12:00:00    714.115784   1862.211914  \n",
            "2004-06-30 13:00:00    724.337402   1825.144531  \n",
            "2004-06-30 14:00:00    717.790222   1844.058105  \n",
            "2004-06-30 15:00:00    726.237976   1833.779419  \n",
            "2004-06-30 16:00:00    748.607544   1789.228149  \n",
            "2004-06-30 17:00:00    690.872681   1865.252808  \n",
            "2004-06-30 18:00:00    575.090515   2185.741699  \n",
            "2004-06-30 19:00:00    595.923950   2237.003174  \n",
            "2004-06-30 20:00:00    639.207581   2072.490234  \n",
            "2004-06-30 21:00:00    696.998047   1908.080322  \n",
            "2004-06-30 22:00:00    710.029419   1863.161621  \n",
            "2004-06-30 23:00:00    706.452759   1863.665649  \n",
            "\n",
            "[2184 rows x 6 columns]\n",
            "T                 0.749714\n",
            "AH                0.034540\n",
            "PT08.S1(CO)      57.966148\n",
            "PT08.S2(NMHC)    69.769768\n",
            "PT08.S3(NOx)     63.821064\n",
            "PT08.S4(NO2)     79.304657\n",
            "dtype: float32\n",
            "0.9590679260653516\n",
            "0.9663200962346226\n",
            "0.9472895023344592\n",
            "0.9257001088041448\n",
            "0.9236015302684436\n",
            "0.9455378829456771\n",
            "acc\n",
            "0.9445861744421165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKWgkLKwHgS5",
        "colab_type": "code",
        "outputId": "41585887-2b17-479a-a0d3-72bf3775ff0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!ps"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:00 run.sh\n",
            "      7 ?        00:00:01 node\n",
            "     22 ?        00:00:04 node\n",
            "     32 ?        00:00:08 jupyter-noteboo\n",
            "    121 ?        00:00:00 tail\n",
            "   1411 ?        00:10:56 python3\n",
            "   1430 ?        00:00:00 python3\n",
            "   1671 ?        00:00:00 ps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gIK-o_aHik5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill 1411"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBj_xZKyn2xV",
        "colab_type": "code",
        "outputId": "71f9f4d8-2893-4256-88a3-dbb16d57300c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9676
        }
      },
      "source": [
        "import os\n",
        "import csv\n",
        "from urllib.request import urlretrieve\n",
        "from urllib.parse import urlparse\n",
        "from zipfile import ZipFile\n",
        "from tensorflow.contrib import rnn\n",
        "\n",
        "def download_file(url, output_dir, overwrite=False):\n",
        "  # URLからファイル名を取得\n",
        "  parse_result = urlparse(url)\n",
        "  file_name = os.path.basename(parse_result.path)\n",
        "  # 出力先ファイルパス\n",
        "  destination = os.path.join(output_dir, file_name)\n",
        "\n",
        "  # 無意味なダウンロードを防ぐため、上書き（overwrite）の指定か未ダウンロードの場合のみダウンロードを実施する\n",
        "  if overwrite or not os.path.exists(destination):\n",
        "    # 出力先ディレクトリの作成\n",
        "    os.makedirs(output_dir)\n",
        "    # ダウンロード\n",
        "    urlretrieve(url, destination)\n",
        "\n",
        "  return destination\n",
        "\n",
        "zip_file = download_file('https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip', 'UCI_data/')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "with ZipFile(zip_file) as z:\n",
        " with z.open('AirQualityUCI.xlsx') as f:\n",
        "   air_quality = pd.read_excel(\n",
        "     f,\n",
        "     index_col=0, parse_dates={'DateTime': [0, 1]}, #1\n",
        "     na_values=[-200.0],                            #2\n",
        "     convert_float=False                            #3\n",
        "   )\n",
        "\n",
        "target_columns = ['T', 'AH', 'PT08.S1(CO)', 'PT08.S2(NMHC)', 'PT08.S3(NOx)', 'PT08.S4(NO2)']\n",
        "air_quality = air_quality[target_columns]\n",
        "\n",
        "print(\"air_quality\")\n",
        "print(type(air_quality))\n",
        "print(air_quality)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 乱数シードの初期化（数値は何でもよい）\n",
        "np.random.seed(12345)\n",
        "\n",
        "# クラス定義\n",
        "class TimeSeriesDataSet:\n",
        "\n",
        " def __init__(self, dataframe):\n",
        "   self.feature_count = len(dataframe.columns)\n",
        "   self.series_length = len(dataframe)\n",
        "   self.series_data = dataframe.astype('float32')\n",
        "\n",
        "\n",
        " def __getitem__(self, n):\n",
        "   return TimeSeriesDataSet(self.series_data[n])\n",
        "\n",
        " def __len__(self):\n",
        "   return len(self.series_data)\n",
        "\n",
        " @property\n",
        " def times(self):\n",
        "   return self.series_data.index\n",
        "\n",
        " def next_batch(self, length, batch_size, train):\n",
        "   \"\"\"\n",
        "   連続したlength時間のデータおよび1時間の誤差測定用データを取得する。\n",
        "   最後の1時間は最終出力データ。\n",
        "   \"\"\"\n",
        "   max_start_index = len(self) - length\n",
        "   design_matrix = []\n",
        "   expectation = []\n",
        "   t_pred = []\n",
        "   while len(design_matrix) < batch_size:\n",
        "     start_index = np.random.choice(max_start_index)\n",
        "     end_index = start_index + length + 1\n",
        "     values = self.series_data[start_index:end_index]\n",
        "     t_values = train.series_data[start_index:end_index]\n",
        "     if (values.count() == length + 1).all():  # 切り出したデータ中に欠損値がない\n",
        "        train_data = values[:-1]\n",
        "        true_value = values[-1:]\n",
        "        teacher_value = t_values[-1:]\n",
        "        design_matrix.append(train_data.as_matrix())\n",
        "        expectation.append(np.reshape(true_value.as_matrix(), [self.feature_count]))\n",
        "        t_pred.append(np.reshape(teacher_value.as_matrix(), [train.feature_count]))\n",
        "   return np.stack(design_matrix), np.stack(expectation), np.stack(t_pred)\n",
        "\n",
        " def append(self, data_point):\n",
        "   dataframe = pd.DataFrame(data_point, columns=self.series_data.columns)\n",
        "   self.series_data = self.series_data.append(dataframe)\n",
        "\n",
        " def tail(self, n):\n",
        "   return TimeSeriesDataSet(self.series_data.tail(n))\n",
        "\n",
        " def as_array(self):\n",
        "   return np.stack([self.series_data.as_matrix()])\n",
        "\n",
        " def mean(self):\n",
        "   return self.series_data.mean()\n",
        "\n",
        " def std(self):\n",
        "   return self.series_data.std()\n",
        "\n",
        " def standardize(self, mean=None, std=None):\n",
        "   if mean is None:\n",
        "     mean = self.mean()\n",
        "   if std is None:\n",
        "     std = self.std()\n",
        "   return TimeSeriesDataSet((self.series_data - mean) / std)\n",
        "\n",
        "\n",
        "dataset = TimeSeriesDataSet(air_quality)\n",
        "print(\"dataset\")\n",
        "print(dataset)\n",
        "#train_dataset = dataset[dataset.times.year < 2005]\n",
        "test_dataset = dataset[dataset.times.year >= 2005]\n",
        "\n",
        "pre0_dataset = dataset[dataset.times.year < 2005]\n",
        "pre_dataset = pre0_dataset[4<=pre0_dataset.times.month]\n",
        "pre_dataset = pre_dataset[pre_dataset.times.month<=6]\n",
        "\n",
        "\n",
        "#add\n",
        "df = pd.read_csv('leak.csv', index_col=0, na_values=[-200.0])\n",
        "#df = df.rename(columns={'Unnamed: 0': 'DateTime'})\n",
        "print(\"df\")\n",
        "print (type(df))\n",
        "print(df)\n",
        "\n",
        "\n",
        "leakset = TimeSeriesDataSet(df)\n",
        "print(\"leakset\")\n",
        "print(leakset)\n",
        "train_dataset = leakset\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "# 再現性の確保のために乱数シードを固定\n",
        "tf.set_random_seed(12345)\n",
        "\n",
        "\n",
        "# パラメーター\n",
        "# 学習時間長\n",
        "SERIES_LENGTH = 72\n",
        "# 特徴量数\n",
        "FEATURE_COUNT = dataset.feature_count #6\n",
        "\n",
        "# 入力（placeholderメソッドの引数は、データ型、テンソルのサイズ）\n",
        "# 訓練データ\n",
        "x = tf.placeholder(tf.float32, [None, SERIES_LENGTH, FEATURE_COUNT])  #batch（16）, 72, 6\n",
        "# 教師データ\n",
        "y = tf.placeholder(tf.float32, [None, FEATURE_COUNT]) #batch（16）, 6\n",
        "t = tf.placeholder(tf.float32, [None, FEATURE_COUNT]) #batch（16）, 6\n",
        "\n",
        "# RNNセルの作成\n",
        "cell = tf.nn.rnn_cell.BasicRNNCell(20)\n",
        "initial_state = cell.zero_state(tf.shape(x)[0], dtype=tf.float32)\n",
        "outputs, last_state = tf.nn.dynamic_rnn(cell, x, initial_state=initial_state, dtype=tf.float32)\n",
        "\n",
        "# 全結合\n",
        "# 重み\n",
        "w = tf.Variable(tf.zeros([20, FEATURE_COUNT]))\n",
        "# バイアス\n",
        "b = tf.Variable([0.1] * FEATURE_COUNT)\n",
        "# 最終出力（予測）\n",
        "#prediction = tf.matmul(last_state[-1], w) + b\n",
        "prediction = tf.matmul(last_state, w) + b\n",
        "\n",
        "# 損失関数（平均絶対誤差：MAE）と最適化（Adam）\n",
        "loss_0 = tf.reduce_mean(tf.map_fn(tf.abs, y - prediction))\n",
        "L2loss_s = tf.nn.l2_loss(prediction - y)\n",
        "L2loss_t = tf.nn.l2_loss(t - y)\n",
        "L2loss_s2 = (tf.nn.l2_loss(prediction - y))**2\n",
        "L2loss_t2 = (tf.nn.l2_loss(t - y))**2\n",
        "L2loss_2 = ((tf.nn.l2_loss(prediction - t))**2)/2\n",
        "\n",
        "optimizer0 = tf.train.AdamOptimizer().minimize(loss_0)\n",
        "optimizer = tf.train.AdamOptimizer().minimize(L2loss_s)\n",
        "optimizer2 = tf.train.AdamOptimizer().minimize(L2loss_s2)\n",
        "optimizer3 = tf.train.AdamOptimizer().minimize(L2loss_2)\n",
        "\n",
        "\n",
        "# バッチサイズ\n",
        "BATCH_SIZE = 16\n",
        "# 学習回数\n",
        "NUM_TRAIN =  5000\n",
        "# 学習中の出力頻度\n",
        "OUTPUT_BY = 1000\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_mean = train_dataset.mean()\n",
        "train_std = train_dataset.std()\n",
        "standardized_train_dataset = train_dataset.standardize() #train_dataset はこの形で今後処理を行う\n",
        "\n",
        "pre_mean = pre_dataset.mean()\n",
        "pre_std = pre_dataset.std()\n",
        "standardized_pre_dataset = pre_dataset.standardize() #pre_dataset はこの形で今後処理を行う\n",
        "\n",
        "\n",
        "########################################\n",
        "# 学習の実行     平均絶対誤差のみ\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_pre_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE, standardized_train_dataset)\n",
        " \n",
        " norm_s = sess.run(loss_0, feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        "    \n",
        " sess.run(optimizer0, feed_dict={x: batch[0], y: batch[1]})\n",
        " \n",
        " if i % OUTPUT_BY == 0:\n",
        "  print('step {:d}, error {:.2f}'.format(i, norm_s))\n",
        "  \n",
        "def rnn_predict(input_dataset):\n",
        " # 標準化\n",
        " previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=pre_mean, std=pre_std)\n",
        " # 予測対象の時刻\n",
        " predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "  \n",
        " # 予測\n",
        " batch_x = previous.as_array()\n",
        " predict_data = prediction.eval({x: batch_x})\n",
        "\n",
        " # 結果のデータフレームを作成\n",
        " df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        " # 標準化の逆操作\n",
        " return pre_mean + pre_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in test_dataset.times:\n",
        " predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        " predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "#hyouka\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc  label only-------------------------------------------------------\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "\n",
        "#abs = abs(test_dataset.series_data - predict_air_quality)\n",
        "\n",
        "#print(tf.reduce_mean(tf.map_fn(test_dataset.series_data - predict_air_quality)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################\n",
        "# 学習の実行    La\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_pre_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE, standardized_train_dataset)\n",
        " \n",
        " norm_s, norm_t = sess.run([L2loss_2, L2loss_t2], feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        " \n",
        " sess.run(optimizer3, feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        " \n",
        " if i % OUTPUT_BY == 0:\n",
        "  print('step {:d}, error {:.2f}'.format(i, norm_s))\n",
        "  \n",
        "def rnn_predict(input_dataset):\n",
        " # 標準化\n",
        " previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=pre_mean, std=pre_std)\n",
        " # 予測対象の時刻\n",
        " predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "  \n",
        " # 予測\n",
        " batch_x = previous.as_array()\n",
        " predict_data = prediction.eval({x: batch_x})\n",
        "\n",
        " # 結果のデータフレームを作成\n",
        " df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        " # 標準化の逆操作\n",
        " return pre_mean + pre_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in test_dataset.times:\n",
        " predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        " predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "#hyouka\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc  La-------------------------------------------------------\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "\n",
        "#abs = abs(test_dataset.series_data - predict_air_quality)\n",
        "\n",
        "#print(tf.reduce_mean(tf.map_fn(test_dataset.series_data - predict_air_quality)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################\n",
        "# 学習の実行    Lb0 m = 5\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "m=5\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_pre_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE, standardized_train_dataset)\n",
        " \n",
        " norm_s, norm_t = sess.run([L2loss_s2, L2loss_t2], feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        " \n",
        " diff = norm_s - norm_t\n",
        " \n",
        "    \n",
        " if norm_s + m > norm_t:\n",
        "   sess.run(optimizer2, feed_dict={x: batch[0], y: batch[1]})\n",
        " \n",
        " if i % OUTPUT_BY == 0:\n",
        "  print('step {:d}, error {:.2f}'.format(i, norm_s))\n",
        "  print(norm_t)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "def rnn_predict(input_dataset):\n",
        " # 標準化\n",
        " previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=pre_mean, std=pre_std)\n",
        " # 予測対象の時刻\n",
        " predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "  \n",
        " # 予測\n",
        " batch_x = previous.as_array()\n",
        " predict_data = prediction.eval({x: batch_x})\n",
        "\n",
        " # 結果のデータフレームを作成\n",
        " df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        " # 標準化の逆操作\n",
        " return pre_mean + pre_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in test_dataset.times:\n",
        " predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        " predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "#hyouka\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc  Lb0  m = 5-------------------------------------------------------\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "\n",
        "#abs = abs(test_dataset.series_data - predict_air_quality)\n",
        "\n",
        "#print(tf.reduce_mean(tf.map_fn(test_dataset.series_data - predict_air_quality)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################\n",
        "# 学習の実行  Lb0 m = 50\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "m=50\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_pre_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE, standardized_train_dataset)\n",
        " \n",
        " norm_s, norm_t = sess.run([L2loss_s2, L2loss_t2], feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        " \n",
        " diff = norm_s - norm_t\n",
        " \n",
        "    \n",
        " if norm_s + m > norm_t:\n",
        "   sess.run(optimizer2, feed_dict={x: batch[0], y: batch[1]})\n",
        " \n",
        " if i % OUTPUT_BY == 0:\n",
        "  print('step {:d}, error {:.2f}'.format(i, norm_s))\n",
        "  print(norm_t)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "def rnn_predict(input_dataset):\n",
        " # 標準化\n",
        " previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=pre_mean, std=pre_std)\n",
        " # 予測対象の時刻\n",
        " predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "  \n",
        " # 予測\n",
        " batch_x = previous.as_array()\n",
        " predict_data = prediction.eval({x: batch_x})\n",
        "\n",
        " # 結果のデータフレームを作成\n",
        " df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        " # 標準化の逆操作\n",
        " return pre_mean + pre_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in test_dataset.times:\n",
        " predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        " predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "#hyouka\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc  Lb0 m = 50-------------------------------------------------------\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "\n",
        "#abs = abs(test_dataset.series_data - predict_air_quality)\n",
        "\n",
        "#print(tf.reduce_mean(tf.map_fn(test_dataset.series_data - predict_air_quality)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################\n",
        "# 学習の実行    Lb0 m = 100\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "m=100\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_pre_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE, standardized_train_dataset)\n",
        " \n",
        " norm_s, norm_t = sess.run([L2loss_s2, L2loss_t2], feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        " \n",
        " diff = norm_s - norm_t\n",
        " \n",
        "    \n",
        " if norm_s + m > norm_t:\n",
        "   sess.run(optimizer2, feed_dict={x: batch[0], y: batch[1]})\n",
        " \n",
        " if i % OUTPUT_BY == 0:\n",
        "  print('step {:d}, error {:.2f}'.format(i, norm_s))\n",
        "  print(norm_t)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "def rnn_predict(input_dataset):\n",
        " # 標準化\n",
        " previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=pre_mean, std=pre_std)\n",
        " # 予測対象の時刻\n",
        " predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "  \n",
        " # 予測\n",
        " batch_x = previous.as_array()\n",
        " predict_data = prediction.eval({x: batch_x})\n",
        "\n",
        " # 結果のデータフレームを作成\n",
        " df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        " # 標準化の逆操作\n",
        " return pre_mean + pre_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in test_dataset.times:\n",
        " predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        " predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "#hyouka\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc  Lb0 m = 100-------------------------------------------------------\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "\n",
        "#abs = abs(test_dataset.series_data - predict_air_quality)\n",
        "\n",
        "#print(tf.reduce_mean(tf.map_fn(test_dataset.series_data - predict_air_quality)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################\n",
        "# 学習の実行   Lb0  m = 500\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "m=500\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_pre_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE, standardized_train_dataset)\n",
        " \n",
        " norm_s, norm_t = sess.run([L2loss_s2, L2loss_t2], feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        " \n",
        " diff = norm_s - norm_t\n",
        " \n",
        "    \n",
        " if norm_s + m > norm_t:\n",
        "   sess.run(optimizer2, feed_dict={x: batch[0], y: batch[1]})\n",
        " \n",
        " if i % OUTPUT_BY == 0:\n",
        "  print('step {:d}, error {:.2f}'.format(i, norm_s))\n",
        "  print(norm_t)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "def rnn_predict(input_dataset):\n",
        " # 標準化\n",
        " previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=pre_mean, std=pre_std)\n",
        " # 予測対象の時刻\n",
        " predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "  \n",
        " # 予測\n",
        " batch_x = previous.as_array()\n",
        " predict_data = prediction.eval({x: batch_x})\n",
        "\n",
        " # 結果のデータフレームを作成\n",
        " df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        " # 標準化の逆操作\n",
        " return pre_mean + pre_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in test_dataset.times:\n",
        " predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        " predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "#hyouka\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc  Lb0 m = 500-------------------------------------------------------\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "\n",
        "#abs = abs(test_dataset.series_data - predict_air_quality)\n",
        "\n",
        "#print(tf.reduce_mean(tf.map_fn(test_dataset.series_data - predict_air_quality)))\n",
        "\n",
        "\n",
        "########################################\n",
        "# 学習の実行   Lb0  m = 0.5\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "m=0.5\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_pre_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE, standardized_train_dataset)\n",
        " \n",
        " norm_s, norm_t = sess.run([L2loss_s2, L2loss_t2], feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        " \n",
        " diff = norm_s - norm_t\n",
        " \n",
        "    \n",
        " if norm_s + m > norm_t:\n",
        "   sess.run(optimizer2, feed_dict={x: batch[0], y: batch[1]})\n",
        " \n",
        " if i % OUTPUT_BY == 0:\n",
        "  print('step {:d}, error {:.2f}'.format(i, norm_s))\n",
        "  print(norm_t)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "def rnn_predict(input_dataset):\n",
        " # 標準化\n",
        " previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=pre_mean, std=pre_std)\n",
        " # 予測対象の時刻\n",
        " predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "  \n",
        " # 予測\n",
        " batch_x = previous.as_array()\n",
        " predict_data = prediction.eval({x: batch_x})\n",
        "\n",
        " # 結果のデータフレームを作成\n",
        " df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        " # 標準化の逆操作\n",
        " return pre_mean + pre_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in test_dataset.times:\n",
        " predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        " predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "#hyouka\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc  Lb0 m = 500-------------------------------------------------------\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "\n",
        "#abs = abs(test_dataset.series_data - predict_air_quality)\n",
        "\n",
        "#print(tf.reduce_mean(tf.map_fn(test_dataset.series_data - predict_air_quality)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################\n",
        "# 学習の実行    Lb m = 5\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "m=5\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_pre_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE, standardized_train_dataset)\n",
        " \n",
        " norm_s, norm_t = sess.run([L2loss_s, L2loss_t], feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        " \n",
        " diff = norm_s - norm_t\n",
        " \n",
        "    \n",
        " if norm_s + m > norm_t:\n",
        "   sess.run(optimizer, feed_dict={x: batch[0], y: batch[1]})\n",
        " \n",
        " if i % OUTPUT_BY == 0:\n",
        "  print('step {:d}, error {:.2f}'.format(i, norm_s))\n",
        "  print(norm_t)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "def rnn_predict(input_dataset):\n",
        " # 標準化\n",
        " previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=pre_mean, std=pre_std)\n",
        " # 予測対象の時刻\n",
        " predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "  \n",
        " # 予測\n",
        " batch_x = previous.as_array()\n",
        " predict_data = prediction.eval({x: batch_x})\n",
        "\n",
        " # 結果のデータフレームを作成\n",
        " df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        " # 標準化の逆操作\n",
        " return pre_mean + pre_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in test_dataset.times:\n",
        " predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        " predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "#hyouka\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc  Lb  m = 5-------------------------------------------------------\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "\n",
        "#abs = abs(test_dataset.series_data - predict_air_quality)\n",
        "\n",
        "#print(tf.reduce_mean(tf.map_fn(test_dataset.series_data - predict_air_quality)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############################################ \n",
        "#学習の実行　　Lb m = 50\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "m=50\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_pre_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE, standardized_train_dataset)\n",
        " \n",
        " norm_s, norm_t = sess.run([L2loss_s, L2loss_t], feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        " \n",
        " diff = norm_s - norm_t\n",
        " \n",
        "    \n",
        " if norm_s + m > norm_t:\n",
        "   sess.run(optimizer, feed_dict={x: batch[0], y: batch[1]})\n",
        " \n",
        " if i % OUTPUT_BY == 0:\n",
        "  print('step {:d}, error {:.2f}'.format(i, norm_s))\n",
        "  print(norm_t)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "def rnn_predict(input_dataset):\n",
        " # 標準化\n",
        " previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=pre_mean, std=pre_std)\n",
        " # 予測対象の時刻\n",
        " predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "  \n",
        " # 予測\n",
        " batch_x = previous.as_array()\n",
        " predict_data = prediction.eval({x: batch_x})\n",
        "\n",
        " # 結果のデータフレームを作成\n",
        " df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        " # 標準化の逆操作\n",
        " return pre_mean + pre_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in test_dataset.times:\n",
        " predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        " predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "#hyouka\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc  Lb m = 50-------------------------------------------------------\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "\n",
        "\n",
        "\n",
        "########################################################\n",
        "#学習の実行　　Lb m = 100\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "m=100\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_pre_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE, standardized_train_dataset)\n",
        " \n",
        " norm_s, norm_t = sess.run([L2loss_s, L2loss_t], feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        " \n",
        " diff = norm_s - norm_t\n",
        " \n",
        "    \n",
        " if norm_s + m > norm_t:\n",
        "   sess.run(optimizer, feed_dict={x: batch[0], y: batch[1]})\n",
        " \n",
        " if i % OUTPUT_BY == 0:\n",
        "  print('step {:d}, error {:.2f}'.format(i, norm_s))\n",
        "  print(norm_t)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "def rnn_predict(input_dataset):\n",
        " # 標準化\n",
        " previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=pre_mean, std=pre_std)\n",
        " # 予測対象の時刻\n",
        " predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "  \n",
        " # 予測\n",
        " batch_x = previous.as_array()\n",
        " predict_data = prediction.eval({x: batch_x})\n",
        "\n",
        " # 結果のデータフレームを作成\n",
        " df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        " # 標準化の逆操作\n",
        " return pre_mean + pre_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in test_dataset.times:\n",
        " predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        " predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "#hyouka\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc  Lb  m = 100-------------------------------------------------------\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################################\n",
        "#学習の実行　　　Lb m = 500\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "m=500\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_pre_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE, standardized_train_dataset)\n",
        " \n",
        " norm_s, norm_t = sess.run([L2loss_s, L2loss_t], feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        " \n",
        " diff = norm_s - norm_t\n",
        " \n",
        "    \n",
        " if norm_s + m > norm_t:\n",
        "   sess.run(optimizer, feed_dict={x: batch[0], y: batch[1]})\n",
        " \n",
        " if i % OUTPUT_BY == 0:\n",
        "  print('step {:d}, error {:.2f}'.format(i, norm_s))\n",
        "  print(norm_t)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "def rnn_predict(input_dataset):\n",
        " # 標準化\n",
        " previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=pre_mean, std=pre_std)\n",
        " # 予測対象の時刻\n",
        " predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "  \n",
        " # 予測\n",
        " batch_x = previous.as_array()\n",
        " predict_data = prediction.eval({x: batch_x})\n",
        "\n",
        " # 結果のデータフレームを作成\n",
        " df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        " # 標準化の逆操作\n",
        " return pre_mean + pre_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in test_dataset.times:\n",
        " predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        " predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "#hyouka\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc  Lb  m = 500-------------------------------------------------------\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################################\n",
        "#学習の実行　　　Lb m = 0.5\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "m = 0.5\n",
        "for i in range(NUM_TRAIN):\n",
        "\n",
        " batch = standardized_pre_dataset.next_batch(SERIES_LENGTH, BATCH_SIZE, standardized_train_dataset)\n",
        " \n",
        " norm_s, norm_t = sess.run([L2loss_s, L2loss_t], feed_dict={x: batch[0], y: batch[1], t:batch[2]})\n",
        " \n",
        " diff = norm_s - norm_t\n",
        " \n",
        "    \n",
        " if norm_s + m > norm_t:\n",
        "   sess.run(optimizer, feed_dict={x: batch[0], y: batch[1]})\n",
        " \n",
        " if i % OUTPUT_BY == 0:\n",
        "  print('step {:d}, error {:.2f}'.format(i, norm_s))\n",
        "  print(norm_t)\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "def rnn_predict(input_dataset):\n",
        " # 標準化\n",
        " previous = TimeSeriesDataSet(input_dataset).tail(SERIES_LENGTH).standardize(mean=pre_mean, std=pre_std)\n",
        " # 予測対象の時刻\n",
        " predict_time = previous.times[-1] + np.timedelta64(1, 'h')\n",
        "  \n",
        " # 予測\n",
        " batch_x = previous.as_array()\n",
        " predict_data = prediction.eval({x: batch_x})\n",
        "\n",
        " # 結果のデータフレームを作成\n",
        " df_standardized  = pd.DataFrame(predict_data, columns=input_dataset.columns, index=[predict_time])\n",
        " # 標準化の逆操作\n",
        " return pre_mean + pre_std * df_standardized\n",
        "\n",
        "predict_air_quality = pd.DataFrame([], columns=air_quality.columns)\n",
        "\n",
        "for current_time in test_dataset.times:\n",
        " predict_result = rnn_predict(air_quality[air_quality.index < current_time])\n",
        " predict_air_quality = predict_air_quality.append(predict_result)\n",
        "\n",
        "#hyouka\n",
        "absmean = np.mean(abs(test_dataset.series_data - predict_air_quality))\n",
        "print(absmean)\n",
        "\n",
        "acc_t = 1-(absmean['T']/18.316054)\n",
        "print(acc_t)\n",
        "\n",
        "acc_ah = 1-(absmean['AH']/1.025530)\n",
        "print(acc_ah)\n",
        "\n",
        "acc_co = 1-(absmean['PT08.S1(CO)']/1099.707856)\n",
        "print(acc_co)\n",
        "\n",
        "acc_nmhc = 1-(absmean['PT08.S2(NMHC)']/939.029205)\n",
        "print(acc_nmhc)\n",
        "\n",
        "acc_nox = 1-(absmean['PT08.S3(NOx)']/835.370973)\n",
        "print(acc_nox)\n",
        "\n",
        "acc_no2 = 1-(absmean['PT08.S4(NO2)']/1456.143486)\n",
        "print(acc_no2)\n",
        "\n",
        "print(\"acc  Lb  m = 500-------------------------------------------------------\")\n",
        "print( (acc_t + acc_ah + acc_co + acc_nmhc + acc_nox + acc_no2)/6 )\n",
        "\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "air_quality\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "                             T        AH  PT08.S1(CO)  PT08.S2(NMHC)  \\\n",
            "DateTime                                                               \n",
            "2004-03-10 18:00:00  13.600000  0.757754  1360.000000    1045.500000   \n",
            "2004-03-10 19:00:00  13.300000  0.725487  1292.250000     954.750000   \n",
            "2004-03-10 20:00:00  11.900000  0.750239  1402.000000     939.250000   \n",
            "2004-03-10 21:00:00  11.000000  0.786713  1375.500000     948.250000   \n",
            "2004-03-10 22:00:00  11.150000  0.788794  1272.250000     835.500000   \n",
            "2004-03-10 23:00:00  11.175000  0.784772  1197.000000     750.250000   \n",
            "2004-03-11 00:00:00  11.325000  0.760312  1185.000000     689.500000   \n",
            "2004-03-11 01:00:00  10.675000  0.770238  1136.250000     672.000000   \n",
            "2004-03-11 02:00:00  10.650000  0.764819  1094.000000     608.500000   \n",
            "2004-03-11 03:00:00  10.250000  0.751657  1009.750000     560.750000   \n",
            "2004-03-11 04:00:00  10.075000  0.746495  1011.000000     526.750000   \n",
            "2004-03-11 05:00:00  11.000000  0.736560  1066.000000     512.000000   \n",
            "2004-03-11 06:00:00  10.450000  0.735295  1051.750000     553.250000   \n",
            "2004-03-11 07:00:00  10.200000  0.741736  1144.000000     667.000000   \n",
            "2004-03-11 08:00:00  10.750000  0.740795  1333.250000     899.750000   \n",
            "2004-03-11 09:00:00  10.500000  0.769111  1351.000000     960.250000   \n",
            "2004-03-11 10:00:00  10.800000  0.755183  1233.250000     827.250000   \n",
            "2004-03-11 11:00:00  10.500000  0.735161  1178.750000     762.000000   \n",
            "2004-03-11 12:00:00   9.525000  0.795054  1236.000000     774.250000   \n",
            "2004-03-11 13:00:00   8.300000  0.839268  1285.500000     868.500000   \n",
            "2004-03-11 14:00:00   8.000000  0.873589  1371.000000    1033.500000   \n",
            "2004-03-11 15:00:00   8.325000  0.877784  1310.000000     932.500000   \n",
            "2004-03-11 16:00:00   9.700000  0.856938  1291.750000     911.500000   \n",
            "2004-03-11 17:00:00   9.775000  0.818501  1383.000000    1019.750000   \n",
            "2004-03-11 18:00:00  10.350000  0.806544  1580.750000    1318.500000   \n",
            "2004-03-11 19:00:00   9.650000  0.831921  1775.500000    1487.750000   \n",
            "2004-03-11 20:00:00   9.650000  0.813314  1640.000000    1404.000000   \n",
            "2004-03-11 21:00:00   9.125000  0.741924  1312.750000    1076.250000   \n",
            "2004-03-11 22:00:00   8.175000  0.690484   964.500000     748.500000   \n",
            "2004-03-11 23:00:00   8.250000  0.665744   912.750000     629.250000   \n",
            "...                        ...       ...          ...            ...   \n",
            "2005-04-03 09:00:00  17.825000  0.620458  1022.250000     715.250000   \n",
            "2005-04-03 10:00:00  21.125000  0.587528   970.250000     676.500000   \n",
            "2005-04-03 11:00:00  24.000000  0.567283   999.750000     779.000000   \n",
            "2005-04-03 12:00:00  26.450000  0.559414   996.000000     780.750000   \n",
            "2005-04-03 13:00:00  28.675000  0.530155   928.000000     700.500000   \n",
            "2005-04-03 14:00:00  28.475000  0.500166   932.750000     721.750000   \n",
            "2005-04-03 15:00:00  30.000000  0.462436   956.000000     783.000000   \n",
            "2005-04-03 16:00:00  29.425000  0.419179   967.500000     826.250000   \n",
            "2005-04-03 17:00:00  28.875000  0.386566   952.500000     816.500000   \n",
            "2005-04-03 18:00:00  22.800001  0.594491  1014.666667     742.666667   \n",
            "2005-04-03 19:00:00  19.925000  0.760784  1248.000000    1018.250000   \n",
            "2005-04-03 20:00:00  17.500000  0.807281  1180.250000     893.750000   \n",
            "2005-04-03 21:00:00  16.450000  0.864238  1101.750000     811.750000   \n",
            "2005-04-03 22:00:00  15.525000  0.857933  1115.500000     803.250000   \n",
            "2005-04-03 23:00:00  14.275000  0.849727  1099.750000     768.750000   \n",
            "2005-04-04 00:00:00  14.175000  0.827454  1012.000000     682.500000   \n",
            "2005-04-04 01:00:00  13.850000  0.805778   944.250000     579.000000   \n",
            "2005-04-04 02:00:00  12.100000  0.792730   911.750000     543.750000   \n",
            "2005-04-04 03:00:00  11.325000  0.788769   887.000000     507.500000   \n",
            "2005-04-04 04:00:00  11.825000  0.774275   864.250000     478.250000   \n",
            "2005-04-04 05:00:00  10.400000  0.754964   888.250000     528.000000   \n",
            "2005-04-04 06:00:00   9.550000  0.753129  1030.500000     730.250000   \n",
            "2005-04-04 07:00:00   9.675000  0.744608  1383.500000    1220.750000   \n",
            "2005-04-04 08:00:00  13.550000  0.755337  1446.000000    1361.500000   \n",
            "2005-04-04 09:00:00  18.150001  0.748652  1296.500000    1102.000000   \n",
            "2005-04-04 10:00:00  21.850000  0.756824  1314.250000    1101.250000   \n",
            "2005-04-04 11:00:00  24.325000  0.711864  1162.500000    1027.000000   \n",
            "2005-04-04 12:00:00  26.900000  0.640649  1142.000000    1062.500000   \n",
            "2005-04-04 13:00:00  28.325000  0.513866  1002.500000     960.500000   \n",
            "2005-04-04 14:00:00  28.500000  0.502804  1070.750000    1047.250000   \n",
            "\n",
            "                     PT08.S3(NOx)  PT08.S4(NO2)  \n",
            "DateTime                                         \n",
            "2004-03-10 18:00:00   1056.250000   1692.000000  \n",
            "2004-03-10 19:00:00   1173.750000   1558.750000  \n",
            "2004-03-10 20:00:00   1140.000000   1554.500000  \n",
            "2004-03-10 21:00:00   1092.000000   1583.750000  \n",
            "2004-03-10 22:00:00   1205.000000   1490.000000  \n",
            "2004-03-10 23:00:00   1336.500000   1393.000000  \n",
            "2004-03-11 00:00:00   1461.750000   1332.750000  \n",
            "2004-03-11 01:00:00   1453.250000   1332.750000  \n",
            "2004-03-11 02:00:00   1579.000000   1276.000000  \n",
            "2004-03-11 03:00:00   1705.000000   1234.750000  \n",
            "2004-03-11 04:00:00   1817.500000   1196.750000  \n",
            "2004-03-11 05:00:00   1918.000000   1182.000000  \n",
            "2004-03-11 06:00:00   1738.250000   1221.250000  \n",
            "2004-03-11 07:00:00   1489.750000   1339.000000  \n",
            "2004-03-11 08:00:00   1136.000000   1517.000000  \n",
            "2004-03-11 09:00:00   1079.000000   1582.750000  \n",
            "2004-03-11 10:00:00   1218.000000   1445.750000  \n",
            "2004-03-11 11:00:00   1327.500000   1361.750000  \n",
            "2004-03-11 12:00:00   1301.250000   1401.250000  \n",
            "2004-03-11 13:00:00   1162.250000   1536.750000  \n",
            "2004-03-11 14:00:00    983.250000   1730.250000  \n",
            "2004-03-11 15:00:00   1081.750000   1646.500000  \n",
            "2004-03-11 16:00:00   1102.500000   1590.750000  \n",
            "2004-03-11 17:00:00   1008.000000   1718.750000  \n",
            "2004-03-11 18:00:00    798.500000   2083.000000  \n",
            "2004-03-11 19:00:00    702.250000   2332.500000  \n",
            "2004-03-11 20:00:00    742.750000   2191.250000  \n",
            "2004-03-11 21:00:00    957.250000   1706.500000  \n",
            "2004-03-11 22:00:00   1325.250000   1332.500000  \n",
            "2004-03-11 23:00:00   1564.500000   1252.250000  \n",
            "...                           ...           ...  \n",
            "2005-04-03 09:00:00    806.000000   1004.250000  \n",
            "2005-04-03 10:00:00    887.500000    930.500000  \n",
            "2005-04-03 11:00:00    804.500000   1000.750000  \n",
            "2005-04-03 12:00:00    806.000000    985.250000  \n",
            "2005-04-03 13:00:00    925.750000    902.000000  \n",
            "2005-04-03 14:00:00    898.750000    889.500000  \n",
            "2005-04-03 15:00:00    856.750000    895.750000  \n",
            "2005-04-03 16:00:00    866.500000    898.250000  \n",
            "2005-04-03 17:00:00    871.500000    891.000000  \n",
            "2005-04-03 18:00:00    850.666667    980.666667  \n",
            "2005-04-03 19:00:00    598.750000   1289.250000  \n",
            "2005-04-03 20:00:00    636.250000   1200.250000  \n",
            "2005-04-03 21:00:00    692.750000   1178.000000  \n",
            "2005-04-03 22:00:00    696.250000   1173.000000  \n",
            "2005-04-03 23:00:00    721.750000   1146.750000  \n",
            "2005-04-04 00:00:00    800.750000   1072.500000  \n",
            "2005-04-04 01:00:00    924.750000   1001.750000  \n",
            "2005-04-04 02:00:00    958.500000   1002.000000  \n",
            "2005-04-04 03:00:00   1046.500000    973.500000  \n",
            "2005-04-04 04:00:00   1116.000000    958.250000  \n",
            "2005-04-04 05:00:00   1076.500000    987.000000  \n",
            "2005-04-04 06:00:00    760.000000   1129.000000  \n",
            "2005-04-04 07:00:00    470.250000   1600.000000  \n",
            "2005-04-04 08:00:00    414.750000   1776.500000  \n",
            "2005-04-04 09:00:00    506.750000   1375.250000  \n",
            "2005-04-04 10:00:00    538.500000   1374.250000  \n",
            "2005-04-04 11:00:00    603.750000   1263.500000  \n",
            "2005-04-04 12:00:00    603.250000   1240.750000  \n",
            "2005-04-04 13:00:00    701.500000   1041.000000  \n",
            "2005-04-04 14:00:00    654.000000   1128.500000  \n",
            "\n",
            "[9357 rows x 6 columns]\n",
            "dataset\n",
            "<__main__.TimeSeriesDataSet object at 0x7f16be7ecac8>\n",
            "df\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "                             T        AH  PT08.S1(CO)  PT08.S2(NMHC)  \\\n",
            "2004-04-01 00:00:00  11.848707  0.829585   1003.79730      759.86590   \n",
            "2004-04-01 01:00:00  11.837768  0.886434   1073.75020      818.40370   \n",
            "2004-04-01 02:00:00  11.255680  0.869652    974.76210      700.25210   \n",
            "2004-04-01 03:00:00  10.570814  0.872321    959.89990      667.20435   \n",
            "2004-04-01 04:00:00   8.993267  0.846044    896.97400      624.40750   \n",
            "2004-04-01 05:00:00  10.340778  0.824634    873.97266      594.03960   \n",
            "2004-04-01 06:00:00  11.194195  0.829192   1016.49190      747.60160   \n",
            "2004-04-01 07:00:00  10.440834  0.840399   1305.83000     1101.17240   \n",
            "2004-04-01 08:00:00  11.415447  0.838755   1640.97380     1499.79720   \n",
            "2004-04-01 09:00:00  14.042244  0.836154   1501.36470     1344.64620   \n",
            "2004-04-01 10:00:00  18.673230  0.841635   1363.82370     1150.92630   \n",
            "2004-04-01 11:00:00  19.694320  0.823264   1224.52860      992.24880   \n",
            "2004-04-01 12:00:00  19.662710  0.844555   1138.03270      897.15320   \n",
            "2004-04-01 13:00:00  21.092724  0.855684   1156.31400      932.00880   \n",
            "2004-04-01 14:00:00  22.182040  0.841422   1149.16740      944.44446   \n",
            "2004-04-01 15:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 16:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 17:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 18:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 19:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 20:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 21:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 22:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-01 23:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-02 00:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-02 01:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-02 02:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-02 03:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-02 04:00:00        NaN       NaN          NaN            NaN   \n",
            "2004-04-02 05:00:00        NaN       NaN          NaN            NaN   \n",
            "...                        ...       ...          ...            ...   \n",
            "2004-06-29 18:00:00  35.393940  1.647656   1321.57010     1328.96240   \n",
            "2004-06-29 19:00:00  35.092630  1.708690   1317.11990     1330.87560   \n",
            "2004-06-29 20:00:00  33.277916  1.719863   1333.55960     1347.75620   \n",
            "2004-06-29 21:00:00  29.750090  1.775487   1151.27510     1063.91020   \n",
            "2004-06-29 22:00:00  29.748539  1.805523   1157.34080     1101.10690   \n",
            "2004-06-29 23:00:00  28.087948  1.821829   1099.95060     1024.32260   \n",
            "2004-06-30 00:00:00  27.660856  1.798853   1100.60190     1048.75280   \n",
            "2004-06-30 01:00:00  26.729397  1.822515   1089.76620     1006.52026   \n",
            "2004-06-30 02:00:00  25.533558  1.782590    913.42410      735.42163   \n",
            "2004-06-30 03:00:00  25.735052  1.789538    898.92175      712.18945   \n",
            "2004-06-30 04:00:00  26.643253  1.791633    855.72840      638.54376   \n",
            "2004-06-30 05:00:00  26.492052  1.798595    847.43010      617.07025   \n",
            "2004-06-30 06:00:00  24.570927  1.779976    988.61750      830.15340   \n",
            "2004-06-30 07:00:00  27.068108  1.777841   1190.47550     1113.97120   \n",
            "2004-06-30 08:00:00  29.110855  1.631191   1370.86550     1391.16020   \n",
            "2004-06-30 09:00:00  30.425910  1.480365   1151.85790     1106.66910   \n",
            "2004-06-30 10:00:00  34.023300  1.641853   1178.15830     1105.02080   \n",
            "2004-06-30 11:00:00  37.059258  1.590128   1186.63110     1150.19740   \n",
            "2004-06-30 12:00:00  39.194885  1.595036   1174.95850     1127.01110   \n",
            "2004-06-30 13:00:00  38.204094  1.648549   1164.80460     1078.36790   \n",
            "2004-06-30 14:00:00  38.101982  1.607734   1158.29330     1106.20140   \n",
            "2004-06-30 15:00:00  39.644638  1.491117   1146.50240     1128.86950   \n",
            "2004-06-30 16:00:00  38.272430  1.467398   1139.05760     1083.14360   \n",
            "2004-06-30 17:00:00  38.151070  1.439455   1196.59440     1163.83540   \n",
            "2004-06-30 18:00:00  36.551216  1.689377   1362.13990     1372.90990   \n",
            "2004-06-30 19:00:00  31.252104  1.950691   1364.51770     1322.24120   \n",
            "2004-06-30 20:00:00  33.253300  1.625263   1256.95080     1287.89930   \n",
            "2004-06-30 21:00:00  29.955578  1.548852   1131.65390     1135.91210   \n",
            "2004-06-30 22:00:00  28.832504  1.596884   1090.97990     1072.54630   \n",
            "2004-06-30 23:00:00  27.763039  1.614898   1081.57400     1064.72440   \n",
            "\n",
            "                     PT08.S3(NOx)  PT08.S4(NO2)  \n",
            "2004-04-01 00:00:00    1110.02300     1408.7947  \n",
            "2004-04-01 01:00:00    1018.52210     1466.8226  \n",
            "2004-04-01 02:00:00    1122.91520     1360.8339  \n",
            "2004-04-01 03:00:00    1170.20750     1349.6761  \n",
            "2004-04-01 04:00:00    1209.53990     1323.4360  \n",
            "2004-04-01 05:00:00    1298.90430     1307.7373  \n",
            "2004-04-01 06:00:00    1117.77150     1434.4210  \n",
            "2004-04-01 07:00:00     816.03860     1787.8912  \n",
            "2004-04-01 08:00:00     558.91670     2213.5708  \n",
            "2004-04-01 09:00:00     688.60460     2052.6296  \n",
            "2004-04-01 10:00:00     751.92456     1802.6910  \n",
            "2004-04-01 11:00:00     872.42490     1628.4413  \n",
            "2004-04-01 12:00:00     963.76807     1545.8209  \n",
            "2004-04-01 13:00:00     939.57800     1580.6472  \n",
            "2004-04-01 14:00:00     926.52230     1579.6088  \n",
            "2004-04-01 15:00:00           NaN           NaN  \n",
            "2004-04-01 16:00:00           NaN           NaN  \n",
            "2004-04-01 17:00:00           NaN           NaN  \n",
            "2004-04-01 18:00:00           NaN           NaN  \n",
            "2004-04-01 19:00:00           NaN           NaN  \n",
            "2004-04-01 20:00:00           NaN           NaN  \n",
            "2004-04-01 21:00:00           NaN           NaN  \n",
            "2004-04-01 22:00:00           NaN           NaN  \n",
            "2004-04-01 23:00:00           NaN           NaN  \n",
            "2004-04-02 00:00:00           NaN           NaN  \n",
            "2004-04-02 01:00:00           NaN           NaN  \n",
            "2004-04-02 02:00:00           NaN           NaN  \n",
            "2004-04-02 03:00:00           NaN           NaN  \n",
            "2004-04-02 04:00:00           NaN           NaN  \n",
            "2004-04-02 05:00:00           NaN           NaN  \n",
            "...                           ...           ...  \n",
            "2004-06-29 18:00:00     606.93640     2130.2520  \n",
            "2004-06-29 19:00:00     610.09860     2167.5376  \n",
            "2004-06-29 20:00:00     600.29860     2185.5273  \n",
            "2004-06-29 21:00:00     711.31287     1915.5381  \n",
            "2004-06-29 22:00:00     658.67140     1954.3150  \n",
            "2004-06-29 23:00:00     701.68225     1889.8844  \n",
            "2004-06-30 00:00:00     688.48640     1909.7688  \n",
            "2004-06-30 01:00:00     713.23300     1875.2422  \n",
            "2004-06-30 02:00:00     940.69820     1636.2572  \n",
            "2004-06-30 03:00:00     950.16840     1617.0094  \n",
            "2004-06-30 04:00:00    1017.41284     1558.8033  \n",
            "2004-06-30 05:00:00    1057.95900     1549.9401  \n",
            "2004-06-30 06:00:00     797.67180     1707.5344  \n",
            "2004-06-30 07:00:00     635.80510     2008.0139  \n",
            "2004-06-30 08:00:00     531.69385     2249.2422  \n",
            "2004-06-30 09:00:00     702.46070     1882.0077  \n",
            "2004-06-30 10:00:00     693.04080     1895.0693  \n",
            "2004-06-30 11:00:00     690.13170     1900.2556  \n",
            "2004-06-30 12:00:00     714.11580     1862.2119  \n",
            "2004-06-30 13:00:00     724.33740     1825.1445  \n",
            "2004-06-30 14:00:00     717.79020     1844.0581  \n",
            "2004-06-30 15:00:00     726.23800     1833.7794  \n",
            "2004-06-30 16:00:00     748.60754     1789.2281  \n",
            "2004-06-30 17:00:00     690.87270     1865.2528  \n",
            "2004-06-30 18:00:00     575.09050     2185.7417  \n",
            "2004-06-30 19:00:00     595.92395     2237.0032  \n",
            "2004-06-30 20:00:00     639.20760     2072.4902  \n",
            "2004-06-30 21:00:00     696.99805     1908.0803  \n",
            "2004-06-30 22:00:00     710.02940     1863.1616  \n",
            "2004-06-30 23:00:00     706.45276     1863.6656  \n",
            "\n",
            "[2184 rows x 6 columns]\n",
            "leakset\n",
            "<__main__.TimeSeriesDataSet object at 0x7f169eb3c908>\n",
            "WARNING:tensorflow:From <ipython-input-1-4241d664bf24>:162: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-1-4241d664bf24>:164: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:87: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:88: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 0, error 0.73\n",
            "step 1000, error 0.31\n",
            "step 2000, error 0.24\n",
            "step 3000, error 0.19\n",
            "step 4000, error 0.29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:99: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "T                  3.365541\n",
            "AH                 0.077758\n",
            "PT08.S1(CO)       77.093079\n",
            "PT08.S2(NMHC)    104.196312\n",
            "PT08.S3(NOx)     122.116989\n",
            "PT08.S4(NO2)     238.586273\n",
            "dtype: float32\n",
            "0.8162518270512916\n",
            "0.9241773215462918\n",
            "0.9298967646792174\n",
            "0.8890382627123045\n",
            "0.8538170548382914\n",
            "0.836151948288591\n",
            "acc  label only-------------------------------------------------------\n",
            "0.874888863185998\n",
            "step 0, error 718.34\n",
            "step 1000, error 17.03\n",
            "step 2000, error 3.69\n",
            "step 3000, error 3.37\n",
            "step 4000, error 1.81\n",
            "T                  3.360172\n",
            "AH                 0.069217\n",
            "PT08.S1(CO)       83.761826\n",
            "PT08.S2(NMHC)    113.570480\n",
            "PT08.S3(NOx)     136.013809\n",
            "PT08.S4(NO2)     295.658112\n",
            "dtype: float32\n",
            "0.8165449680521517\n",
            "0.9325062748343216\n",
            "0.9238326569147257\n",
            "0.8790554332687878\n",
            "0.8371815473601552\n",
            "0.7969581195707347\n",
            "acc  La-------------------------------------------------------\n",
            "0.864346500000146\n",
            "step 0, error 2887.03\n",
            "17.556393\n",
            "step 1000, error 103.04\n",
            "65.01578\n",
            "step 2000, error 67.32\n",
            "26.567234\n",
            "step 3000, error 41.07\n",
            "36.905704\n",
            "step 4000, error 41.99\n",
            "14.113397\n",
            "T                  4.147911\n",
            "AH                 0.068974\n",
            "PT08.S1(CO)       81.760506\n",
            "PT08.S2(NMHC)    123.497810\n",
            "PT08.S3(NOx)     141.719223\n",
            "PT08.S4(NO2)     375.390594\n",
            "dtype: float32\n",
            "0.7735368876429287\n",
            "0.9327427902471646\n",
            "0.9256525219582776\n",
            "0.868483525638833\n",
            "0.8303517507754474\n",
            "0.7422021949817507\n",
            "acc  Lb0  m = 5-------------------------------------------------------\n",
            "0.8454949452074003\n",
            "step 0, error 2294.15\n",
            "50.518692\n",
            "step 1000, error 110.59\n",
            "96.58743\n",
            "step 2000, error 142.54\n",
            "113.009636\n",
            "step 3000, error 61.59\n",
            "65.23177\n",
            "step 4000, error 11.92\n",
            "19.32377\n",
            "T                  2.346362\n",
            "AH                 0.075013\n",
            "PT08.S1(CO)       66.172073\n",
            "PT08.S2(NMHC)    122.642433\n",
            "PT08.S3(NOx)     102.081558\n",
            "PT08.S4(NO2)     360.581116\n",
            "dtype: float32\n",
            "0.871895898695457\n",
            "0.9268545772142799\n",
            "0.9398275887516641\n",
            "0.8693944421393114\n",
            "0.877800927340171\n",
            "0.7523725380160398\n",
            "acc  Lb0 m = 50-------------------------------------------------------\n",
            "0.8730243286928205\n",
            "step 0, error 3993.97\n",
            "31.737827\n",
            "step 1000, error 126.22\n",
            "25.631804\n",
            "step 2000, error 11.05\n",
            "3.1924477\n",
            "step 3000, error 73.19\n",
            "27.438377\n",
            "step 4000, error 151.71\n",
            "267.46255\n",
            "T                  2.644942\n",
            "AH                 0.129935\n",
            "PT08.S1(CO)       73.412903\n",
            "PT08.S2(NMHC)    104.369492\n",
            "PT08.S3(NOx)     148.806610\n",
            "PT08.S4(NO2)     343.360870\n",
            "dtype: float32\n",
            "0.8555943562748487\n",
            "0.8732993290364901\n",
            "0.9332432678083631\n",
            "0.8888538386011664\n",
            "0.8218676313673855\n",
            "0.7641984641880765\n",
            "acc  Lb0 m = 100-------------------------------------------------------\n",
            "0.8561761478793883\n",
            "step 0, error 3363.56\n",
            "8.823194\n",
            "step 1000, error 185.57\n",
            "35.33412\n",
            "step 2000, error 101.68\n",
            "62.12357\n",
            "step 3000, error 25.76\n",
            "19.663515\n",
            "step 4000, error 40.35\n",
            "49.637524\n",
            "T                  2.752094\n",
            "AH                 0.077082\n",
            "PT08.S1(CO)       73.396156\n",
            "PT08.S2(NMHC)     95.842361\n",
            "PT08.S3(NOx)     153.895615\n",
            "PT08.S4(NO2)     285.368195\n",
            "dtype: float32\n",
            "0.8497441756853485\n",
            "0.9248372689298529\n",
            "0.9332584959627358\n",
            "0.8979346319157397\n",
            "0.8157757216876347\n",
            "0.8040246738568467\n",
            "acc  Lb0 m = 500-------------------------------------------------------\n",
            "0.870929161339693\n",
            "step 0, error 1344.30\n",
            "19.960335\n",
            "step 1000, error 123.69\n",
            "72.394104\n",
            "step 2000, error 36.48\n",
            "7.6790934\n",
            "step 3000, error 63.51\n",
            "70.08693\n",
            "step 4000, error 20.58\n",
            "15.548922\n",
            "T                  3.103207\n",
            "AH                 0.086728\n",
            "PT08.S1(CO)       66.835686\n",
            "PT08.S2(NMHC)    108.849815\n",
            "PT08.S3(NOx)     164.998810\n",
            "PT08.S4(NO2)     357.150909\n",
            "dtype: float32\n",
            "0.8305744724623195\n",
            "0.9154306539232345\n",
            "0.9392241445168139\n",
            "0.8840826091573453\n",
            "0.8024843870000579\n",
            "0.7547282167879518\n",
            "acc  Lb0 m = 500-------------------------------------------------------\n",
            "0.8544207473079538\n",
            "step 0, error 58.92\n",
            "3.8974693\n",
            "step 1000, error 7.05\n",
            "4.1275473\n",
            "step 2000, error 5.86\n",
            "2.7904828\n",
            "step 3000, error 4.79\n",
            "4.956748\n",
            "step 4000, error 6.59\n",
            "6.61821\n",
            "T                  1.983761\n",
            "AH                 0.125828\n",
            "PT08.S1(CO)       95.103981\n",
            "PT08.S2(NMHC)     95.037712\n",
            "PT08.S3(NOx)     125.070045\n",
            "PT08.S4(NO2)     286.457092\n",
            "dtype: float32\n",
            "0.8916927895860678\n",
            "0.8773039407318979\n",
            "0.9135188673071857\n",
            "0.8987915268331106\n",
            "0.8502820309616008\n",
            "0.8032768782477276\n",
            "acc  Lb  m = 5-------------------------------------------------------\n",
            "0.8724776722779316\n",
            "step 0, error 50.98\n",
            "3.270438\n",
            "step 1000, error 5.64\n",
            "3.18907\n",
            "step 2000, error 3.68\n",
            "2.3672075\n",
            "step 3000, error 5.11\n",
            "6.7582283\n",
            "step 4000, error 7.21\n",
            "5.2739935\n",
            "T                  2.626091\n",
            "AH                 0.052395\n",
            "PT08.S1(CO)       73.108658\n",
            "PT08.S2(NMHC)     96.650459\n",
            "PT08.S3(NOx)     118.110886\n",
            "PT08.S4(NO2)     294.744659\n",
            "dtype: float32\n",
            "0.8566235649566871\n",
            "0.9489091181907807\n",
            "0.9335199276443888\n",
            "0.897074064603187\n",
            "0.8586126530157552\n",
            "0.7975854287316929\n",
            "acc  Lb m = 50-------------------------------------------------------\n",
            "0.8820541261904152\n",
            "step 0, error 47.93\n",
            "2.0924115\n",
            "step 1000, error 6.70\n",
            "4.851248\n",
            "step 2000, error 6.48\n",
            "3.2228334\n",
            "step 3000, error 4.10\n",
            "3.8129592\n",
            "step 4000, error 7.95\n",
            "7.986742\n",
            "T                  3.696393\n",
            "AH                 0.094682\n",
            "PT08.S1(CO)       71.137245\n",
            "PT08.S2(NMHC)     94.086082\n",
            "PT08.S3(NOx)     110.674652\n",
            "PT08.S4(NO2)     282.893799\n",
            "dtype: float32\n",
            "0.7981883405989594\n",
            "0.9076745902951566\n",
            "0.9353125970773981\n",
            "0.8998049454079587\n",
            "0.867514367057605\n",
            "0.8057239540278897\n",
            "acc  Lb  m = 100-------------------------------------------------------\n",
            "0.8690364657441613\n",
            "step 0, error 40.82\n",
            "2.1656058\n",
            "step 1000, error 6.60\n",
            "2.5744762\n",
            "step 2000, error 11.72\n",
            "7.8367586\n",
            "step 3000, error 8.63\n",
            "5.494779\n",
            "step 4000, error 5.87\n",
            "5.794166\n",
            "T                  3.312251\n",
            "AH                 0.062703\n",
            "PT08.S1(CO)       78.966530\n",
            "PT08.S2(NMHC)     97.379349\n",
            "PT08.S3(NOx)     158.171860\n",
            "PT08.S4(NO2)     300.745331\n",
            "dtype: float32\n",
            "0.8191613165694195\n",
            "0.9388576018279396\n",
            "0.9281931747460469\n",
            "0.8962978486330648\n",
            "0.8106567443046517\n",
            "0.7934644946036953\n",
            "acc  Lb  m = 500-------------------------------------------------------\n",
            "0.8644385301141363\n",
            "step 0, error 54.97\n",
            "6.781189\n",
            "step 1000, error 8.00\n",
            "5.2037873\n",
            "step 2000, error 5.89\n",
            "4.4257803\n",
            "step 3000, error 5.41\n",
            "6.201086\n",
            "step 4000, error 5.12\n",
            "3.6186142\n",
            "T                  3.682055\n",
            "AH                 0.092906\n",
            "PT08.S1(CO)       84.652695\n",
            "PT08.S2(NMHC)    110.531174\n",
            "PT08.S3(NOx)     119.995926\n",
            "PT08.S4(NO2)     335.356903\n",
            "dtype: float32\n",
            "0.7989711390167535\n",
            "0.909407295453099\n",
            "0.9230225607280299\n",
            "0.8822920808878839\n",
            "0.856356122271775\n",
            "0.7696951527782532\n",
            "acc  Lb  m = 500-------------------------------------------------------\n",
            "0.8566240585226325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBauoToaqBTy",
        "colab_type": "code",
        "outputId": "db3b8b3c-73b4-4194-9e3f-4ae1f3ac5025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!ps"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:00 run.sh\n",
            "      6 ?        00:00:01 node\n",
            "     23 ?        00:00:03 node\n",
            "     33 ?        00:00:07 jupyter-noteboo\n",
            "    126 ?        00:00:00 tail\n",
            "   1183 ?        00:52:48 python3\n",
            "   1217 ?        00:00:00 python3\n",
            "   1790 ?        00:00:00 ps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoF4uYPHqB_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill  1183"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm17eyxNS2UN",
        "colab_type": "text"
      },
      "source": [
        "88.89\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSXW6cCLoQ0c",
        "colab_type": "text"
      },
      "source": [
        "5月\n",
        "0.9562003119735011\n",
        "0.966117349018336\n",
        "0.9483239553704763\n",
        "0.9290228464660454\n",
        "0.9229807231117118\n",
        "0.9489187915725145"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on5aGmFWTPFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}